from pathlib import Path
from os.path import dirname

src_dir = Path("resources")
src_query_dir = src_dir / "query"
src_bench_dir = src_dir / "bench"

res_dir = Path("results")

res_inter_dir = res_dir / "intermediate"
res_asm_dir = res_inter_dir / "asm" / "{hap}"
res_ref_dir = res_inter_dir / "ref" / "{ref}"
res_compbed_dir = res_inter_dir / "comparison" / "bed" / "{ref}"

final_dir = res_dir / "final" / "{ref}"

HAPLOTYPES = ["pat", "mat"]

ASM = {
    "mat": "https://s3-us-west-2.amazonaws.com/human-pangenomics/T2T/HG002/assemblies/hg002v1.1.mat.fasta.gz",
    "pat": "https://s3-us-west-2.amazonaws.com/human-pangenomics/T2T/HG002/assemblies/hg002v1.1.pat.fasta.gz",
}

REF = {
    "GRCh38": "https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/release/references/GRCh38/GCA_000001405.15_GRCh38_no_alt_analysis_set.fasta.gz",
}

ERRORS = {
    "pat": "https://s3-us-west-2.amazonaws.com/human-pangenomics/T2T/HG002/assemblies/polishing/HG002/v1.1/benchmark/results/hprc_hg002_curated_vs_v1.1/benchpatv1.1/hg002_curated_pat.errortype.hg002v1.1.bed",
    "mat": "https://s3-us-west-2.amazonaws.com/human-pangenomics/T2T/HG002/assemblies/polishing/HG002/v1.1/benchmark/results/hprc_hg002_curated_vs_v1.1/benchmatv1.1/hg002_curated_mat.errortype.hg002v1.1.bed",
}


################################################################################
# download a bunch of stuff


rule clone_liftover_scripts:
    output:
        directory(src_dir / "tools/liftover"),
    shell:
        """
        git clone \
        --depth 1 \
        --branch v0.2.0 \
        https://github.com/mobinasri/flagger.git \
        {output}
        """


rule download_asm:
    output:
        src_dir / "asm" / "{hap}.fa.gz",
    params:
        url=lambda w: ASM[w.hap],
    shell:
        "curl -SsLqf {params.url} > {output}"


use rule download_asm as download_ref with:
    output:
        src_dir / "references" / "{ref}.fa.gz",
    params:
        url=lambda w: REF[w.ref],


rule download_errors:
    output:
        src_dir / "errors" / "{hap}.bed",
    params:
        url=lambda w: ERRORS[w.hap],
    shell:
        "curl -SsLqf {params.url} > {output}"


################################################################################
# make pafs


rule make_asm_genome:
    input:
        rules.download_asm.output,
    output:
        res_asm_dir / "genome.txt",
    conda:
        "envs/minimap.yml"
    shell:
        """
        samtools faidx {input} -o - | \
        cut -f1-2 > {output}
        """

# for testing
rule list_test_asm_chrs:
    input:
        rules.make_asm_genome.output,
    output:
        res_asm_dir / "chrs_filtered.txt",
    shell:
        """
        cat {input} | \
        cut -f1 | \
        grep -E '(chr21|chr22)' > {output}
        """


rule filter_test_asm:
    input:
        fa=rules.download_asm.output,
        regions=rules.list_test_asm_chrs.output,
    output:
        res_asm_dir / "filtered.fa.gz",
    conda:
        "envs/minimap.yml"
    shell:
        """
        samtools faidx {input.fa} \
        $(cat {input.regions} | tr '\n' ' ') | \
        bgzip -c \
        > {output}
        """


rule index_test_asm:
    input:
        rules.filter_test_asm.output,
    output:
        rules.filter_test_asm.output[0] + ".fai",
    conda:
        "envs/minimap.yml"
    shell:
        """
        samtools faidx {input}
        """


rule list_test_ref_chrs:
    input:
        rules.download_ref.output,
    output:
        res_ref_dir / "chrs_filtered.txt",
    conda:
        "envs/minimap.yml"
    shell:
        """
        samtools faidx {input} -o - | \
        cut -f1 | \
        grep -E '(chr21|chr22)' > {output}
        """


use rule filter_test_asm as filter_test_ref with:
    input:
        fa=rules.download_ref.output,
        regions=rules.list_test_ref_chrs.output,
    output:
        res_ref_dir / "filtered.fa.gz",


use rule index_test_asm as index_test_ref with:
    input:
        rules.filter_test_ref.output,
    output:
        rules.filter_test_ref.output[0] + ".fai",


use rule index_test_asm as index_asm with:
    input:
        rules.download_asm.output,
    output:
        rules.download_asm.output[0] + ".fai",


use rule index_test_asm as index_ref with:
    input:
        rules.download_ref.output,
    output:
        rules.download_ref.output[0] + ".fai",


rule run_minimap:
    input:
        haplotype=rules.filter_test_asm.output,
        _haplotype_idx=rules.index_test_asm.output,
        ref=rules.filter_test_ref.output,
        _ref_idx=rules.index_test_ref.output,
    output:
        res_compbed_dir / "{hap}.paf",
    conda:
        "envs/minimap.yml"
    log:
        res_compbed_dir / "{hap}.log",
    threads: 16
    resources:
        mem_mb=48000,
    shell:
        """
        minimap2 -c --paf-no-hit -t{threads} --cs -z200000,10000,200 -xasm5 \
          {input.ref} \
          {input.haplotype} \
          2> {log} > {output}
        """


################################################################################
# run liftover


rule slop_errors:
    input:
        rules.download_errors.output,
    output:
        res_asm_dir / "errors_slop50.bed",
    shell:
        """
        awk '{FS=OFS=\"\t\"} {print $1,$2-50,$3+50,$10,$11,$12}' {input} \
        > {output}
        """


rule split_errors:
    input:
        bed=rules.download_errors.output,
        genome=lambda w: expand(rules.make_asm_genome.output, hap = w.mapped_hap),
    output:
        res_asm_dir / "errors_slop50_{mapped_hap}.bed",
    params:
        chr_filter=lambda w: "PATERNAL" if w.mapped_hap == "pat" else "MATERNAL",
    conda:
        "envs/minimap.yml"
    shell:
        """
        grep {params.chr_filter} {input.bed} | \
        grep -E '(chr21|chr22)' | \
        sed 's/\t/;/g4' | \
        bedtools sort -i stdin -g {input.genome} \
        > {output} 
        """


rule run_liftover:
    input:
        paf=lambda w: expand(
            rules.run_minimap.output,
            allow_missing=True,
            hap=w.mapped_hap,
        ),
        bed=rules.split_errors.output,
        tooldir=rules.clone_liftover_scripts.output,
    output:
        projectable=final_dir / "hprc_{hap}_q100_{mapped_hap}_projectable.bed",
        projected=final_dir / "hprc_{hap}_q100_{mapped_hap}_projected.bed",
    threads: 8
    resources:
        mem_mb=32000,
    shell:
        """
        python {input.tooldir}/programs/src/project_blocks_multi_thread.py \
        --mode asm2ref \
        --paf {input.paf} \
        --blocks {input.bed} \
        --outputProjectable {output.projectable} \
        --outputProjection {output.projected} \
        --threads {threads}
        """


rule all:
    input:
        expand(
            rules.run_liftover.output,
            ref=["GRCh38"],
            hap=HAPLOTYPES,
            mapped_hap=HAPLOTYPES,
        ),
